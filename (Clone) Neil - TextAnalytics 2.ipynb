{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad2cd0a2-6d7f-46f4-a170-d64eee024447",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting unidecode\n  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 235.5/235.5 kB 4.4 MB/s eta 0:00:00\nInstalling collected packages: unidecode\nSuccessfully installed unidecode-1.3.8\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95140a63-d1b9-4930-8d2d-099788a28fdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting openpyxl\n  Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 250.9/250.9 kB 3.8 MB/s eta 0:00:00\nCollecting et-xmlfile\n  Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\nInstalling collected packages: et-xmlfile, openpyxl\nSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b25462c-e26d-443e-8936-fc9af9c53b2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados: 8365 registros\nCargando archivo N1: /Workspace/Users/jenisalvarado@bcp.com.pe/GENERACION BASES | CARGA DE RESPUESTAS | TIPIFICACION COMENTARIOS/Herramienta_comentarios/n1.txt.txt\nArchivo N1 cargado: 5 categorías\nCargando archivo N2: /Workspace/Users/jenisalvarado@bcp.com.pe/GENERACION BASES | CARGA DE RESPUESTAS | TIPIFICACION COMENTARIOS/Herramienta_comentarios/n2.txt.txt\nArchivo N2 cargado: categorías para 5 categorías N1\nCargando archivo N3: /Workspace/Users/jenisalvarado@bcp.com.pe/GENERACION BASES | CARGA DE RESPUESTAS | TIPIFICACION COMENTARIOS/Herramienta_comentarios/n3.txt.txt\nArchivo N3 cargado\nCargando archivo de exclusiones: /Workspace/Users/jenisalvarado@bcp.com.pe/GENERACION BASES | CARGA DE RESPUESTAS | TIPIFICACION COMENTARIOS/Herramienta_comentarios/excludes.txt\nArchivo de exclusiones cargado: 4 categorías con exclusiones\nTotal de patrones N1: 1545\nTotal de patrones N2: 2566\nTotal de patrones N3: 2042\nTotal de patrones de exclusión: 340\n  - funcionalidad: 97 exclusiones\n  - seguridad: 81 exclusiones\n  - diseno: 81 exclusiones\n  - tarifas: 81 exclusiones\nIniciando procesamiento de comentarios...\nProcesados 100/8365 comentarios (1.2%)...\nProcesados 200/8365 comentarios (2.4%)...\nProcesados 300/8365 comentarios (3.6%)...\nProcesados 400/8365 comentarios (4.8%)...\nProcesados 500/8365 comentarios (6.0%)...\nProcesados 600/8365 comentarios (7.2%)...\nProcesados 700/8365 comentarios (8.4%)...\nProcesados 800/8365 comentarios (9.6%)...\nProcesados 900/8365 comentarios (10.8%)...\nProcesados 1000/8365 comentarios (12.0%)...\nProcesados 1100/8365 comentarios (13.2%)...\nProcesados 1200/8365 comentarios (14.3%)...\nProcesados 1300/8365 comentarios (15.5%)...\nProcesados 1400/8365 comentarios (16.7%)...\nProcesados 1500/8365 comentarios (17.9%)...\nProcesados 1600/8365 comentarios (19.1%)...\nProcesados 1700/8365 comentarios (20.3%)...\nProcesados 1800/8365 comentarios (21.5%)...\nProcesados 1900/8365 comentarios (22.7%)...\nProcesados 2000/8365 comentarios (23.9%)...\nProcesados 2100/8365 comentarios (25.1%)...\nProcesados 2200/8365 comentarios (26.3%)...\nProcesados 2300/8365 comentarios (27.5%)...\nProcesados 2400/8365 comentarios (28.7%)...\nProcesados 2500/8365 comentarios (29.9%)...\nProcesados 2600/8365 comentarios (31.1%)...\nProcesados 2700/8365 comentarios (32.3%)...\nProcesados 2800/8365 comentarios (33.5%)...\nProcesados 2900/8365 comentarios (34.7%)...\nProcesados 3000/8365 comentarios (35.9%)...\nProcesados 3100/8365 comentarios (37.1%)...\nProcesados 3200/8365 comentarios (38.3%)...\nProcesados 3300/8365 comentarios (39.5%)...\nProcesados 3400/8365 comentarios (40.6%)...\nProcesados 3500/8365 comentarios (41.8%)...\nProcesados 3600/8365 comentarios (43.0%)...\nProcesados 3700/8365 comentarios (44.2%)...\nProcesados 3800/8365 comentarios (45.4%)...\nProcesados 3900/8365 comentarios (46.6%)...\nProcesados 4000/8365 comentarios (47.8%)...\nProcesados 4100/8365 comentarios (49.0%)...\nProcesados 4200/8365 comentarios (50.2%)...\nProcesados 4300/8365 comentarios (51.4%)...\nProcesados 4400/8365 comentarios (52.6%)...\nProcesados 4500/8365 comentarios (53.8%)...\nProcesados 4600/8365 comentarios (55.0%)...\nProcesados 4700/8365 comentarios (56.2%)...\nProcesados 4800/8365 comentarios (57.4%)...\nProcesados 4900/8365 comentarios (58.6%)...\nProcesados 5000/8365 comentarios (59.8%)...\nProcesados 5100/8365 comentarios (61.0%)...\nProcesados 5200/8365 comentarios (62.2%)...\nProcesados 5300/8365 comentarios (63.4%)...\nProcesados 5400/8365 comentarios (64.6%)...\nProcesados 5500/8365 comentarios (65.8%)...\nProcesados 5600/8365 comentarios (66.9%)...\nProcesados 5700/8365 comentarios (68.1%)...\nProcesados 5800/8365 comentarios (69.3%)...\nProcesados 5900/8365 comentarios (70.5%)...\nProcesados 6000/8365 comentarios (71.7%)...\nProcesados 6100/8365 comentarios (72.9%)...\nProcesados 6200/8365 comentarios (74.1%)...\nProcesados 6300/8365 comentarios (75.3%)...\nProcesados 6400/8365 comentarios (76.5%)...\nProcesados 6500/8365 comentarios (77.7%)...\nProcesados 6600/8365 comentarios (78.9%)...\nProcesados 6700/8365 comentarios (80.1%)...\nProcesados 6800/8365 comentarios (81.3%)...\nProcesados 6900/8365 comentarios (82.5%)...\nProcesados 7000/8365 comentarios (83.7%)...\nProcesados 7100/8365 comentarios (84.9%)...\nProcesados 7200/8365 comentarios (86.1%)...\nProcesados 7300/8365 comentarios (87.3%)...\nProcesados 7400/8365 comentarios (88.5%)...\nProcesados 7500/8365 comentarios (89.7%)...\nProcesados 7600/8365 comentarios (90.9%)...\nProcesados 7700/8365 comentarios (92.1%)...\nProcesados 7800/8365 comentarios (93.2%)...\nProcesados 7900/8365 comentarios (94.4%)...\nProcesados 8000/8365 comentarios (95.6%)...\nProcesados 8100/8365 comentarios (96.8%)...\nProcesados 8200/8365 comentarios (98.0%)...\nProcesados 8300/8365 comentarios (99.2%)...\n\n===== RESULTADOS DE LA CLASIFICACIÓN =====\nTotal registros procesados: 8365\nTiempo de ejecución: 4688.54 segundos (78.14 minutos)\n\nDistribución por categoría N1:\n  - Sin Comentario: 5049 (60.4%)\n  - funcionalidad: 1336 (16.0%)\n  - otros: 984 (11.8%)\n  - noespecifica: 524 (6.3%)\n  - seguridad: 181 (2.2%)\n  - tarifas: 175 (2.1%)\n  - diseno: 90 (1.1%)\n  - Sin categoría N1: 26 (0.3%)\n\nDistribución por categoría N2:\n  - Sin categoría N2: 6194 (74.0%)\n  - operaciones: 369 (4.4%)\n  - inestabilidad: 257 (3.1%)\n  - prestamos: 238 (2.8%)\n  - agencias: 232 (2.8%)\n  - reclamos: 150 (1.8%)\n  - token: 97 (1.2%)\n  - comision: 89 (1.1%)\n  - login: 82 (1.0%)\n  - comentarios genericos: 68 (0.8%)\n\nDistribución por categoría N3:\n  - Sin categoría N3: 7684 (91.9%)\n  - no hay campanas: 114 (1.4%)\n  - mantenimiento: 84 (1.0%)\n  - no puede realizar no especificado: 56 (0.7%)\n  - lentitud: 55 (0.7%)\n  - no puede realizar monetarias: 39 (0.5%)\n  - tiempo de espera: 38 (0.5%)\n  - no puede ingresar: 36 (0.4%)\n  - no funciona: 33 (0.4%)\n  - no puede realizar consultas: 31 (0.4%)\n\nDistribución de sentimiento:\n  - neutral: 7683 (91.8%)\n  - negativo: 443 (5.3%)\n  - positivo: 239 (2.9%)\n\nGuardando resultados en Excel: /Workspace/Users/jenisalvarado@bcp.com.pe/GENERACION BASES | CARGA DE RESPUESTAS | TIPIFICACION COMENTARIOS/Herramienta_comentarios/EXPORT_topicos_digitales_nuevaversion.xlsx\nArchivo Excel guardado correctamente.\n\nProceso completado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from unidecode import unidecode\n",
    "from datetime import datetime\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    if pd.isnull(texto):\n",
    "        return \"\"\n",
    "    \n",
    "    texto = texto.lower()\n",
    "    texto = unidecode(texto)\n",
    "    texto = texto.replace(\",\", \" \")\n",
    "    texto = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", texto)\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
    "    return texto\n",
    "\n",
    "def limpiar_topico(texto):\n",
    "    if pd.isnull(texto):\n",
    "        return \"\"\n",
    "    \n",
    "    texto = unidecode(texto)\n",
    "    texto = re.sub(r\"[^a-zA-Z0-9_\\s]\", \"\", texto)\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
    "    return texto\n",
    "\n",
    "def es_palabra_comun(palabra):\n",
    "    palabras_comunes = {\n",
    "        \"bien\", \"esta\", \"todo\", \"para\", \"por\", \"con\", \"los\", \"las\", \"que\", \"una\", \"uno\", \n",
    "        \"mas\", \"muy\", \"hay\", \"solo\", \"como\", \"pero\", \"cuando\", \"hora\", \"hacer\", \"haces\",\n",
    "        \"dan\", \"dar\", \"deben\", \"estan\", \"esta\", \"en\", \"el\", \"la\", \"de\", \"del\", \"y\", \"o\",\n",
    "        \"me\", \"mi\", \"se\", \"su\", \"lo\", \"tan\", \"te\", \"tu\", \"si\", \"no\", \"mis\", \"sus\", \"fue\",\n",
    "        \"son\", \"ser\", \"sin\", \"fue\", \"era\", \"eso\", \"esto\", \"esa\", \"ese\", \"este\", \"estos\",\n",
    "        \"aqui\", \"ahi\", \"alla\", \"cada\", \"vez\", \"otro\", \"otra\", \"otros\", \"otras\", \"hasta\",\n",
    "        \"desde\", \"sobre\", \"bajo\", \"entre\", \"hacia\", \"contra\", \"segun\", \"durante\", \"mediante\",\n",
    "        \"al\", \"ya\", \"mas\", \"menos\", \"poco\", \"mucho\", \"dentro\", \"fuera\", \"antes\", \"despues\",\n",
    "        \"entonces\", \"luego\", \"ahora\", \"siempre\", \"nunca\", \"a\", \"ha\"\n",
    "    }\n",
    "    return palabra.lower().strip() in palabras_comunes\n",
    "\n",
    "def normalizar_palabra(palabra):\n",
    "    palabra = palabra.lower().strip()\n",
    "    \n",
    "    sufijos = ['s', 'es', 'ar', 'er', 'ir', 'ando', 'endo', 'cion', 'sion']\n",
    "    for sufijo in sufijos:\n",
    "        if len(palabra) > len(sufijo) + 3 and palabra.endswith(sufijo):\n",
    "            palabra = palabra[:-len(sufijo)]\n",
    "            break\n",
    "    \n",
    "    return palabra\n",
    "\n",
    "def similitud_levenshtein(s1, s2):\n",
    "    if s1 == s2:\n",
    "        return 1.0\n",
    "        \n",
    "    len_s1, len_s2 = len(s1), len(s2)\n",
    "    \n",
    "    if len_s1 == 0: \n",
    "        return 0.0\n",
    "    if len_s2 == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    matriz = [[0 for _ in range(len_s2 + 1)] for _ in range(len_s1 + 1)]\n",
    "    \n",
    "    for i in range(len_s1 + 1):\n",
    "        matriz[i][0] = i\n",
    "    for j in range(len_s2 + 1):\n",
    "        matriz[0][j] = j\n",
    "        \n",
    "    for i in range(1, len_s1 + 1):\n",
    "        for j in range(1, len_s2 + 1):\n",
    "            if s1[i-1] == s2[j-1]:\n",
    "                costo = 0\n",
    "            else:\n",
    "                costo = 1\n",
    "                \n",
    "            matriz[i][j] = min(\n",
    "                matriz[i-1][j] + 1,\n",
    "                matriz[i][j-1] + 1,\n",
    "                matriz[i-1][j-1] + costo\n",
    "            )\n",
    "    \n",
    "    distancia = matriz[len_s1][len_s2]\n",
    "    \n",
    "    max_len = max(len_s1, len_s2)\n",
    "    if max_len == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    similitud = 1.0 - (distancia / max_len)\n",
    "    \n",
    "    return similitud\n",
    "\n",
    "def similitud_palabras_mejorada(palabra1, palabra2):\n",
    "    pal1 = palabra1.lower().strip()\n",
    "    pal2 = palabra2.lower().strip()\n",
    "    \n",
    "    if pal1 == pal2:\n",
    "        return 1.0\n",
    "    \n",
    "    if len(pal1) <= 3 or len(pal2) <= 3:\n",
    "        return 1.0 if pal1 == pal2 else 0.0\n",
    "    \n",
    "    if es_palabra_comun(pal1) or es_palabra_comun(pal2):\n",
    "        return 1.0 if pal1 == pal2 else 0.0\n",
    "    \n",
    "    norm_pal1 = normalizar_palabra(pal1)\n",
    "    norm_pal2 = normalizar_palabra(pal2)\n",
    "    \n",
    "    if norm_pal1 == norm_pal2:\n",
    "        return 0.95\n",
    "    \n",
    "    similitud = similitud_levenshtein(pal1, pal2)\n",
    "    \n",
    "    longitud_promedio = (len(pal1) + len(pal2)) / 2\n",
    "    umbral_base = 0.7\n",
    "    \n",
    "    if longitud_promedio > 8:\n",
    "        umbral_adaptado = umbral_base - 0.05\n",
    "    elif longitud_promedio < 5:\n",
    "        umbral_adaptado = umbral_base + 0.15\n",
    "    else:\n",
    "        umbral_adaptado = umbral_base\n",
    "    \n",
    "    return similitud if similitud >= umbral_adaptado else 0.0\n",
    "\n",
    "def buscar_patron_exacto(comentario, frase_exacta):\n",
    "    comentario_norm = ' '.join(comentario.split())\n",
    "    frase_norm = ' '.join(frase_exacta.split())\n",
    "    \n",
    "    return comentario_norm == frase_norm\n",
    "\n",
    "def cargar_n1(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"El archivo {path} no existe.\")\n",
    "    \n",
    "    dic_n1 = {}\n",
    "    categoria_actual = None\n",
    "    \n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for linea_num, linea in enumerate(f, 1):\n",
    "            linea = linea.strip()\n",
    "            if not linea:\n",
    "                continue\n",
    "            \n",
    "            if linea.startswith(\"#\") and not linea.startswith(\"##\"):\n",
    "                categoria_actual = limpiar_texto(linea.replace(\"#\", \"\").strip())\n",
    "                if categoria_actual in dic_n1:\n",
    "                    print(f\"Advertencia en línea {linea_num}: Categoría N1 '{categoria_actual}' ya existe. Sobrescribiendo.\")\n",
    "                dic_n1[categoria_actual] = {\"patron\": [], \"exacto\": []}\n",
    "            else:\n",
    "                es_exacto = linea.startswith(\"- \")\n",
    "                if es_exacto:\n",
    "                    frase = limpiar_texto(linea[2:])\n",
    "                else:\n",
    "                    frase = limpiar_texto(linea)\n",
    "                \n",
    "                frase = ' '.join(frase.split())\n",
    "                if categoria_actual and frase:\n",
    "                    if es_exacto:\n",
    "                        dic_n1[categoria_actual][\"exacto\"].append(frase)\n",
    "                    else:\n",
    "                        dic_n1[categoria_actual][\"patron\"].append(frase)\n",
    "                elif frase:\n",
    "                    print(f\"Advertencia en línea {linea_num}: Frase clave '{frase}' encontrada sin una categoría N1 previa.\")\n",
    "    \n",
    "    return dic_n1\n",
    "\n",
    "# Función para cargar el archivo de exclusiones\n",
    "def cargar_exclusiones(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Advertencia: El archivo de exclusiones {path} no existe.\")\n",
    "        return {}\n",
    "    \n",
    "    dic_exclusiones = {}\n",
    "    categoria_actual = None\n",
    "    \n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for linea_num, linea in enumerate(f, 1):\n",
    "            linea = linea.strip()\n",
    "            if not linea:\n",
    "                continue\n",
    "            \n",
    "            if linea.startswith(\"#\"):\n",
    "                categoria_actual = limpiar_texto(linea.replace(\"#\", \"\").strip())\n",
    "                if categoria_actual in dic_exclusiones:\n",
    "                    print(f\"Advertencia en línea {linea_num}: Categoría '{categoria_actual}' ya existe en exclusiones. Continuando con la existente.\")\n",
    "                else:\n",
    "                    dic_exclusiones[categoria_actual] = []\n",
    "            elif categoria_actual:\n",
    "                patron = limpiar_texto(linea)\n",
    "                if patron:\n",
    "                    dic_exclusiones[categoria_actual].append(patron)\n",
    "            else:\n",
    "                print(f\"Advertencia en línea {linea_num}: Patrón de exclusión '{linea}' encontrado sin una categoría previa.\")\n",
    "    \n",
    "    return dic_exclusiones\n",
    "\n",
    "def cargar_n2(path, dic_n1):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"El archivo {path} no existe.\")\n",
    "    \n",
    "    dic_n2 = {}\n",
    "    categoria_n1_actual = None\n",
    "    subcategoria_n2_actual = None\n",
    "    \n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for linea_num, linea in enumerate(f, 1):\n",
    "            linea = linea.strip()\n",
    "\n",
    "            if not linea:\n",
    "                continue\n",
    "\n",
    "            if linea.startswith(\"#\") and not linea.startswith(\"##\"):\n",
    "                categoria_n1 = limpiar_texto(linea.replace(\"#\", \"\").strip())\n",
    "                if categoria_n1 not in dic_n1:\n",
    "                    print(f\"Advertencia en línea {linea_num}: Categoría N1 '{categoria_n1}' en n2.txt no existe en n1.txt.\")\n",
    "                categoria_n1_actual = categoria_n1\n",
    "                if categoria_n1_actual not in dic_n2:\n",
    "                    dic_n2[categoria_n1_actual] = {}\n",
    "                subcategoria_n2_actual = None\n",
    "\n",
    "            elif linea.startswith(\"##\"):\n",
    "                if categoria_n1_actual is None:\n",
    "                    print(f\"Advertencia en línea {linea_num}: Subcategoría N2 encontrada antes de una categoría N1.\")\n",
    "                    continue\n",
    "                \n",
    "                subcategoria_n2 = limpiar_texto(linea.replace(\"##\", \"\").strip())\n",
    "                if subcategoria_n2 in dic_n2[categoria_n1_actual]:\n",
    "                    print(f\"Advertencia en línea {linea_num}: Subcategoría N2 '{subcategoria_n2}' ya existe bajo la categoría N1 '{categoria_n1_actual}'. Se ignorará la duplicación.\")\n",
    "                    continue\n",
    "                dic_n2[categoria_n1_actual][subcategoria_n2] = {\"patron\": [], \"exacto\": []}\n",
    "                subcategoria_n2_actual = subcategoria_n2\n",
    "            else:\n",
    "                if categoria_n1_actual is None or subcategoria_n2_actual is None:\n",
    "                    print(f\"Advertencia en línea {linea_num}: Frase clave encontrada fuera de contexto en la línea: '{linea}'\")\n",
    "                    continue\n",
    "                \n",
    "                es_exacto = linea.startswith(\"- \")\n",
    "                if es_exacto:\n",
    "                    frase = limpiar_texto(linea[2:])\n",
    "                else:\n",
    "                    frase = limpiar_texto(linea)\n",
    "                    \n",
    "                frase = ' '.join(frase.split())\n",
    "                \n",
    "                if frase:\n",
    "                    if es_exacto:\n",
    "                        dic_n2[categoria_n1_actual][subcategoria_n2_actual][\"exacto\"].append(frase)\n",
    "                    else:\n",
    "                        dic_n2[categoria_n1_actual][subcategoria_n2_actual][\"patron\"].append(frase)\n",
    "    \n",
    "    return dic_n2\n",
    "\n",
    "def cargar_n3(path, dic_n1, dic_n2):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"El archivo {path} no existe.\")\n",
    "    \n",
    "    dic_n3 = {}\n",
    "    categoria_n1_actual = None\n",
    "    subcategoria_n2_actual = None\n",
    "    subcategoria_n3_actual = None\n",
    "    \n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for linea_num, linea in enumerate(f, 1):\n",
    "            linea = linea.strip()\n",
    "\n",
    "            if not linea:\n",
    "                continue\n",
    "\n",
    "            if linea.startswith(\"#\") and not linea.startswith(\"##\") and not linea.startswith(\"###\"):\n",
    "                categoria_n1 = limpiar_texto(linea.replace(\"#\", \"\").strip())\n",
    "                if categoria_n1 not in dic_n1:\n",
    "                    print(f\"Advertencia en línea {linea_num}: Categoría N1 '{categoria_n1}' en n3.txt no existe en n1.txt.\")\n",
    "                categoria_n1_actual = categoria_n1\n",
    "                if categoria_n1_actual not in dic_n3:\n",
    "                    dic_n3[categoria_n1_actual] = {}\n",
    "                subcategoria_n2_actual = None\n",
    "                subcategoria_n3_actual = None\n",
    "\n",
    "            elif linea.startswith(\"##\") and not linea.startswith(\"###\"):\n",
    "                if categoria_n1_actual is None:\n",
    "                    print(f\"Advertencia en línea {linea_num}: Subcategoría N2 encontrada antes de una categoría N1.\")\n",
    "                    continue\n",
    "                \n",
    "                subcategoria_n2 = limpiar_texto(linea.replace(\"##\", \"\").strip())\n",
    "                if categoria_n1_actual not in dic_n2 or subcategoria_n2 not in dic_n2[categoria_n1_actual]:\n",
    "                    print(f\"Advertencia en línea {linea_num}: Subcategoría N2 '{subcategoria_n2}' en n3.txt no existe en n2.txt para la categoría N1 '{categoria_n1_actual}'.\")\n",
    "                \n",
    "                if subcategoria_n2 not in dic_n3.get(categoria_n1_actual, {}):\n",
    "                    dic_n3[categoria_n1_actual][subcategoria_n2] = {}\n",
    "                subcategoria_n2_actual = subcategoria_n2\n",
    "                subcategoria_n3_actual = None\n",
    "                \n",
    "            elif linea.startswith(\"###\"):\n",
    "                if categoria_n1_actual is None or subcategoria_n2_actual is None:\n",
    "                    print(f\"Advertencia en línea {linea_num}: Subcategoría N3 encontrada antes de categorías N1 o N2.\")\n",
    "                    continue\n",
    "                \n",
    "                subcategoria_n3 = limpiar_texto(linea.replace(\"###\", \"\").strip())\n",
    "                if subcategoria_n3 in dic_n3.get(categoria_n1_actual, {}).get(subcategoria_n2_actual, {}):\n",
    "                    print(f\"Advertencia en línea {linea_num}: Subcategoría N3 '{subcategoria_n3}' ya existe bajo la categoría N1 '{categoria_n1_actual}' y N2 '{subcategoria_n2_actual}'. Se ignorará la duplicación.\")\n",
    "                    continue\n",
    "                \n",
    "                dic_n3[categoria_n1_actual][subcategoria_n2_actual][subcategoria_n3] = {\"patron\": [], \"exacto\": []}\n",
    "                subcategoria_n3_actual = subcategoria_n3\n",
    "                \n",
    "            else:\n",
    "                if categoria_n1_actual is None or subcategoria_n2_actual is None or subcategoria_n3_actual is None:\n",
    "                    print(f\"Advertencia en línea {linea_num}: Frase clave encontrada fuera de contexto en la línea: '{linea}'\")\n",
    "                    continue\n",
    "                \n",
    "                es_exacto = linea.startswith(\"- \")\n",
    "                if es_exacto:\n",
    "                    frase = limpiar_texto(linea[2:])\n",
    "                else:\n",
    "                    frase = limpiar_texto(linea)\n",
    "                    \n",
    "                frase = ' '.join(frase.split())\n",
    "                \n",
    "                if frase:\n",
    "                    if es_exacto:\n",
    "                        dic_n3[categoria_n1_actual][subcategoria_n2_actual][subcategoria_n3_actual][\"exacto\"].append(frase)\n",
    "                    else:\n",
    "                        dic_n3[categoria_n1_actual][subcategoria_n2_actual][subcategoria_n3_actual][\"patron\"].append(frase)\n",
    "    \n",
    "    return dic_n3\n",
    "\n",
    "def buscar_patron_avanzado(comentario, patron, max_gap=5):\n",
    "    palabras_patron = patron.split()\n",
    "    palabras_comentario = comentario.split()\n",
    "    \n",
    "    if len(palabras_patron) <= 2:\n",
    "        palabras_significativas = [p for p in palabras_patron if not es_palabra_comun(p)]\n",
    "        \n",
    "        if not palabras_significativas and len(palabras_patron) == 1:\n",
    "            return palabras_patron[0] in palabras_comentario\n",
    "            \n",
    "        if len(palabras_significativas) > 0:\n",
    "            umbral_local = 0.85\n",
    "            encontrados = 0\n",
    "            \n",
    "            for palabra_patron in palabras_significativas:\n",
    "                for palabra_comentario in palabras_comentario:\n",
    "                    similitud = similitud_palabras_mejorada(palabra_comentario, palabra_patron)\n",
    "                    if similitud >= umbral_local:\n",
    "                        encontrados += 1\n",
    "                        break\n",
    "            \n",
    "            return encontrados == len(palabras_significativas)\n",
    "    \n",
    "    indices_por_palabra = []\n",
    "    \n",
    "    for palabra_patron in palabras_patron:\n",
    "        indices = []\n",
    "        for i, palabra_comentario in enumerate(palabras_comentario):\n",
    "            if not es_palabra_comun(palabra_patron) and len(palabra_patron) > 3:\n",
    "                similitud = similitud_palabras_mejorada(palabra_comentario, palabra_patron)\n",
    "                if similitud >= 0.85:\n",
    "                    indices.append(i)\n",
    "            elif palabra_comentario == palabra_patron:\n",
    "                indices.append(i)\n",
    "        \n",
    "        if not indices:\n",
    "            return False\n",
    "            \n",
    "        indices_por_palabra.append(indices)\n",
    "    \n",
    "    return verificar_secuencia_valida(indices_por_palabra, max_gap)\n",
    "\n",
    "def verificar_secuencia_valida(indices_por_palabra, max_gap):\n",
    "    if len(indices_por_palabra) == 1:\n",
    "        return True\n",
    "        \n",
    "    def buscar_secuencia(posicion_actual, indice_actual, visitados=None):\n",
    "        if visitados is None:\n",
    "            visitados = set()\n",
    "            \n",
    "        visitados.add((posicion_actual, indice_actual))\n",
    "        \n",
    "        if indice_actual == len(indices_por_palabra) - 1:\n",
    "            return True\n",
    "            \n",
    "        for siguiente_indice in range(indice_actual + 1, len(indices_por_palabra)):\n",
    "            if (posicion_actual, siguiente_indice) in visitados:\n",
    "                continue\n",
    "                \n",
    "            for siguiente_pos in indices_por_palabra[siguiente_indice]:\n",
    "                distancia = siguiente_pos - posicion_actual\n",
    "                if 0 < distancia <= max_gap + 1:\n",
    "                    if buscar_secuencia(siguiente_pos, siguiente_indice, visitados):\n",
    "                        return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    for pos_inicial in indices_por_palabra[0]:\n",
    "        if buscar_secuencia(pos_inicial, 0):\n",
    "            return True\n",
    "            \n",
    "    return False\n",
    "\n",
    "# Función para verificar si un comentario debe excluirse de una categoría\n",
    "def debe_excluirse(comentario, categoria, dic_exclusiones):\n",
    "    if categoria not in dic_exclusiones:\n",
    "        return False\n",
    "    \n",
    "    for patron_exclusion in dic_exclusiones[categoria]:\n",
    "        if buscar_patron_avanzado(comentario, patron_exclusion, max_gap=6):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Función modificada para tener en cuenta las exclusiones\n",
    "def obtener_categorias_n1_mejorado(comentario_limpio, dic_n1, dic_exclusiones):\n",
    "    categorias_encontradas = []\n",
    "    puntuaciones_categorias = {}\n",
    "    \n",
    "    for categoria_n1, tipos in dic_n1.items():\n",
    "        # Primero verificar si el comentario debe excluirse de esta categoría\n",
    "        if debe_excluirse(comentario_limpio, categoria_n1, dic_exclusiones):\n",
    "            continue\n",
    "            \n",
    "        for frase in tipos[\"exacto\"]:\n",
    "            if buscar_patron_exacto(comentario_limpio, frase):\n",
    "                puntuaciones_categorias[categoria_n1] = 100\n",
    "                categorias_encontradas.append(categoria_n1)\n",
    "                break\n",
    "    \n",
    "    if categorias_encontradas:\n",
    "        return categorias_encontradas\n",
    "    \n",
    "    for categoria_n1, tipos in dic_n1.items():\n",
    "        # Verificar exclusiones antes de buscar patrones\n",
    "        if debe_excluirse(comentario_limpio, categoria_n1, dic_exclusiones):\n",
    "            continue\n",
    "            \n",
    "        for frase in tipos[\"patron\"]:\n",
    "            if buscar_patron_avanzado(comentario_limpio, frase, max_gap=6):\n",
    "                palabras = frase.split()\n",
    "                puntuacion = len(palabras) * 5\n",
    "                \n",
    "                palabras_significativas = [p for p in palabras if not es_palabra_comun(p)]\n",
    "                puntuacion += len(palabras_significativas) * 10\n",
    "                \n",
    "                if categoria_n1 not in puntuaciones_categorias or puntuacion > puntuaciones_categorias[categoria_n1]:\n",
    "                    puntuaciones_categorias[categoria_n1] = puntuacion\n",
    "    \n",
    "    categorias_ordenadas = sorted(puntuaciones_categorias.keys(), \n",
    "                                 key=lambda c: puntuaciones_categorias[c],\n",
    "                                 reverse=True)\n",
    "    \n",
    "    categorias_filtradas = [c for c in categorias_ordenadas \n",
    "                           if puntuaciones_categorias[c] >= 15]\n",
    "    \n",
    "    return categorias_filtradas[:1] if categorias_filtradas else []\n",
    "\n",
    "def obtener_subcategorias_n2_mejorado(comentario_limpio, categoria_n1, dic_n2):\n",
    "    subcategorias_encontradas = []\n",
    "    puntuaciones_subcategorias = {}\n",
    "    \n",
    "    if categoria_n1 in dic_n2:\n",
    "        for subcategoria_n2, tipos in dic_n2[categoria_n1].items():\n",
    "            for frase in tipos[\"exacto\"]:\n",
    "                if buscar_patron_exacto(comentario_limpio, frase):\n",
    "                    puntuaciones_subcategorias[subcategoria_n2] = 100\n",
    "                    subcategorias_encontradas.append(subcategoria_n2)\n",
    "                    break\n",
    "        \n",
    "        if subcategorias_encontradas:\n",
    "            return subcategorias_encontradas\n",
    "        \n",
    "        for subcategoria_n2, tipos in dic_n2[categoria_n1].items():\n",
    "            for frase in tipos[\"patron\"]:\n",
    "                if buscar_patron_avanzado(comentario_limpio, frase, max_gap=6):\n",
    "                    palabras = frase.split()\n",
    "                    puntuacion = len(palabras) * 5\n",
    "                    \n",
    "                    palabras_significativas = [p for p in palabras if not es_palabra_comun(p)]\n",
    "                    puntuacion += len(palabras_significativas) * 10\n",
    "                    \n",
    "                    if subcategoria_n2 not in puntuaciones_subcategorias or puntuacion > puntuaciones_subcategorias[subcategoria_n2]:\n",
    "                        puntuaciones_subcategorias[subcategoria_n2] = puntuacion\n",
    "        \n",
    "        subcategorias_ordenadas = sorted(puntuaciones_subcategorias.keys(), \n",
    "                                        key=lambda c: puntuaciones_subcategorias[c],\n",
    "                                        reverse=True)\n",
    "        \n",
    "        subcategorias_filtradas = [c for c in subcategorias_ordenadas \n",
    "                                  if puntuaciones_subcategorias[c] >= 15]\n",
    "        \n",
    "        return subcategorias_filtradas[:1] if subcategorias_filtradas else []\n",
    "    \n",
    "    return []\n",
    "\n",
    "def obtener_subcategorias_n3_mejorado(comentario_limpio, categoria_n1, subcategoria_n2, dic_n3):\n",
    "    subcategorias_encontradas = []\n",
    "    puntuaciones_subcategorias = {}\n",
    "    \n",
    "    if categoria_n1 in dic_n3 and subcategoria_n2 in dic_n3[categoria_n1]:\n",
    "        for subcategoria_n3, tipos in dic_n3[categoria_n1][subcategoria_n2].items():\n",
    "            for frase in tipos[\"exacto\"]:\n",
    "                if buscar_patron_exacto(comentario_limpio, frase):\n",
    "                    puntuaciones_subcategorias[subcategoria_n3] = 100\n",
    "                    subcategorias_encontradas.append(subcategoria_n3)\n",
    "                    break\n",
    "        \n",
    "        if subcategorias_encontradas:\n",
    "            return subcategorias_encontradas\n",
    "        \n",
    "        for subcategoria_n3, tipos in dic_n3[categoria_n1][subcategoria_n2].items():\n",
    "            for frase in tipos[\"patron\"]:\n",
    "                if buscar_patron_avanzado(comentario_limpio, frase, max_gap=6):\n",
    "                    palabras = frase.split()\n",
    "                    puntuacion = len(palabras) * 5\n",
    "                    \n",
    "                    palabras_significativas = [p for p in palabras if not es_palabra_comun(p)]\n",
    "                    puntuacion += len(palabras_significativas) * 10\n",
    "                    \n",
    "                    if subcategoria_n3 not in puntuaciones_subcategorias or puntuacion > puntuaciones_subcategorias[subcategoria_n3]:\n",
    "                        puntuaciones_subcategorias[subcategoria_n3] = puntuacion\n",
    "        \n",
    "        subcategorias_ordenadas = sorted(puntuaciones_subcategorias.keys(), \n",
    "                                        key=lambda c: puntuaciones_subcategorias[c],\n",
    "                                        reverse=True)\n",
    "        \n",
    "        subcategorias_filtradas = [c for c in subcategorias_ordenadas \n",
    "                                  if puntuaciones_subcategorias[c] >= 15]\n",
    "        \n",
    "        return subcategorias_filtradas[:1] if subcategorias_filtradas else []\n",
    "    \n",
    "    return []\n",
    "\n",
    "def analizar_sentimiento_mejorado(comentario):\n",
    "    palabras_positivas = {\n",
    "        \"bien\": 1, \"buena\": 1, \"bueno\": 1, \"excelente\": 2, \"ok\": 0.5, \"perfecto\": 2, \n",
    "        \"correcto\": 1, \"satisfecho\": 2, \"agradable\": 1, \"rapido\": 1, \"eficiente\": 1, \n",
    "        \"util\": 1, \"practico\": 1, \"facil\": 1, \"sencillo\": 1, \"mejor\": 1, \"genial\": 2,\n",
    "        \"encanta\": 2, \"gusta\": 1, \"contento\": 1, \"gracias\": 1, \"felicitaciones\": 2,\n",
    "        \"adecuado\": 0.5, \"ideal\": 1, \"feliz\": 1, \"maravilloso\": 2, \"increible\": 2\n",
    "    }\n",
    "    \n",
    "    palabras_negativas = {\n",
    "        \"mal\": 1, \"mala\": 1, \"malo\": 1, \"pesimo\": 2, \"terrible\": 2, \"horrible\": 2, \n",
    "        \"lento\": 1, \"deficiente\": 1, \"problema\": 1, \"error\": 1, \"falla\": 1, \n",
    "        \"no sirve\": 2, \"no funciona\": 2, \"complicado\": 1, \"dificil\": 1, \"peor\": 1.5,\n",
    "        \"molesto\": 1, \"molestia\": 1, \"inutil\": 1.5, \"fatal\": 2, \"desastre\": 2,\n",
    "        \"frustrante\": 1.5, \"cansado\": 0.5, \"demorado\": 1, \"engorroso\": 1, \"confuso\": 1,\n",
    "        \"aburrido\": 0.5, \"tedioso\": 1, \"queja\": 1, \"reclamo\": 1.5, \"decepciona\": 1.5\n",
    "    }\n",
    "    \n",
    "    negaciones = [\"no\", \"ni\", \"nunca\", \"jamas\", \"tampoco\", \"nada\", \"ningun\", \"ninguna\"]\n",
    "    \n",
    "    intensificadores = [\"muy\", \"mucho\", \"demasiado\", \"bastante\", \"extremadamente\", \"super\", \"totalmente\"]\n",
    "    \n",
    "    palabras = comentario.lower().split()\n",
    "    sentimiento = 0\n",
    "    negacion_activa = False\n",
    "    intensificador_activo = False\n",
    "    \n",
    "    for i, palabra in enumerate(palabras):\n",
    "        if palabra in negaciones:\n",
    "            negacion_activa = True\n",
    "            continue\n",
    "            \n",
    "        if palabra in intensificadores:\n",
    "            intensificador_activo = True\n",
    "            continue\n",
    "            \n",
    "        palabra_encontrada = False\n",
    "        for p_pos, valor in palabras_positivas.items():\n",
    "            if ' ' in p_pos:\n",
    "                if i + len(p_pos.split()) <= len(palabras):\n",
    "                    frase_comentario = ' '.join(palabras[i:i+len(p_pos.split())])\n",
    "                    if frase_comentario == p_pos:\n",
    "                        palabra_encontrada = True\n",
    "                        if negacion_activa:\n",
    "                            sentimiento -= valor * 1.2\n",
    "                        else:\n",
    "                            sentimiento += valor * (1.5 if intensificador_activo else 1)\n",
    "                        break\n",
    "            elif similitud_palabras_mejorada(palabra, p_pos) > 0.9:\n",
    "                palabra_encontrada = True\n",
    "                if negacion_activa:\n",
    "                    sentimiento -= valor * 1.2\n",
    "                else:\n",
    "                    sentimiento += valor * (1.5 if intensificador_activo else 1)\n",
    "                break\n",
    "        \n",
    "        if not palabra_encontrada:\n",
    "            for p_neg, valor in palabras_negativas.items():\n",
    "                if ' ' in p_neg:\n",
    "                    if i + len(p_neg.split()) <= len(palabras):\n",
    "                        frase_comentario = ' '.join(palabras[i:i+len(p_neg.split())])\n",
    "                        if frase_comentario == p_neg:\n",
    "                            if negacion_activa:\n",
    "                                sentimiento += valor * 0.8\n",
    "                            else:\n",
    "                                sentimiento -= valor * (1.5 if intensificador_activo else 1)\n",
    "                            break\n",
    "                elif similitud_palabras_mejorada(palabra, p_neg) > 0.9:\n",
    "                    if negacion_activa:\n",
    "                        sentimiento += valor * 0.8\n",
    "                    else:\n",
    "                        sentimiento -= valor * (1.5 if intensificador_activo else 1)\n",
    "                    break\n",
    "        \n",
    "        negacion_activa = False\n",
    "        intensificador_activo = False\n",
    "    \n",
    "    if len(palabras) <= 5 and sentimiento != 0:\n",
    "        sentimiento *= 1.2\n",
    "        \n",
    "    if sentimiento > 1:\n",
    "        return \"positivo\"\n",
    "    elif sentimiento < -0.5:\n",
    "        return \"negativo\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "def es_comentario_generico(comentario):\n",
    "    palabras_genericas = [\"todo\", \"nada\", \"algo\", \"mucho\", \"poco\", \"bien\", \"mal\"]\n",
    "    palabras = comentario.split()\n",
    "    \n",
    "    if len(palabras) <= 2:\n",
    "        for palabra in palabras:\n",
    "            if palabra in palabras_genericas:\n",
    "                return True\n",
    "    \n",
    "    palabras_significativas = [p for p in palabras if not es_palabra_comun(p)]\n",
    "    \n",
    "    if len(palabras_significativas) < max(1, len(palabras) * 0.3):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "try:\n",
    "    df = spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            ID_ENCUESTA, \n",
    "            CODINTERNOCOMPUTACIONAL, \n",
    "            CANAL, \n",
    "            '' AS EDAD, \n",
    "            FECHA_tRANSACCION AS FEC_TRANSACCION, \n",
    "            FECHA_RESPUESTA as FEC_RESPUESTA, \n",
    "            SEGMENTO, \n",
    "            NPS AS P1_NPS, \n",
    "            COMENTARIO_NPS\n",
    "        FROM catalog_lhcl_prod_bcp.bcp_edv_expclie_001.banca_online_resp \n",
    "        WHERE codmes in ( '202412', '202501', '202502', '202503') \n",
    "        and canal = 'Banca Móvil' \n",
    "        and NPS in ('0', '1', '2', '3', '4', '5', '6')\n",
    "    \"\"\")\n",
    "\n",
    "    df = df.toPandas()\n",
    "    print(f\"Datos cargados: {len(df)} registros\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al ejecutar la consulta SQL: {str(e)}\")\n",
    "    print(\"Continuando con DataFrame vacío...\")\n",
    "    df = pd.DataFrame(columns=[\n",
    "        \"ID_ENCUESTA\", \"CODINTERNOCOMPUTACIONAL\", \"CANAL\", \"EDAD\",\n",
    "        \"FEC_TRANSACCION\", \"FEC_RESPUESTA\", \"SEGMENTO\", \"P1_NPS\", \"COMENTARIO_NPS\"\n",
    "    ])\n",
    "\n",
    "n1_path = \"/Workspace/Users/jenisalvarado@bcp.com.pe/GENERACION BASES | CARGA DE RESPUESTAS | TIPIFICACION COMENTARIOS/Herramienta_comentarios/n1.txt.txt\"\n",
    "n2_path = \"/Workspace/Users/jenisalvarado@bcp.com.pe/GENERACION BASES | CARGA DE RESPUESTAS | TIPIFICACION COMENTARIOS/Herramienta_comentarios/n2.txt.txt\"\n",
    "n3_path = \"/Workspace/Users/jenisalvarado@bcp.com.pe/GENERACION BASES | CARGA DE RESPUESTAS | TIPIFICACION COMENTARIOS/Herramienta_comentarios/n3.txt.txt\"\n",
    "excludes_path = \"/Workspace/Users/jenisalvarado@bcp.com.pe/GENERACION BASES | CARGA DE RESPUESTAS | TIPIFICACION COMENTARIOS/Herramienta_comentarios/excludes.txt\"\n",
    "\n",
    "try:\n",
    "    print(f\"Cargando archivo N1: {n1_path}\")\n",
    "    dic_n1 = cargar_n1(n1_path)\n",
    "    print(f\"Archivo N1 cargado: {len(dic_n1)} categorías\")\n",
    "    \n",
    "    print(f\"Cargando archivo N2: {n2_path}\")\n",
    "    dic_n2 = cargar_n2(n2_path, dic_n1)\n",
    "    print(f\"Archivo N2 cargado: categorías para {len(dic_n2)} categorías N1\")\n",
    "    \n",
    "    print(f\"Cargando archivo N3: {n3_path}\")\n",
    "    dic_n3 = cargar_n3(n3_path, dic_n1, dic_n2)\n",
    "    print(f\"Archivo N3 cargado\")\n",
    "    \n",
    "    # Cargar exclusiones\n",
    "    print(f\"Cargando archivo de exclusiones: {excludes_path}\")\n",
    "    dic_exclusiones = cargar_exclusiones(excludes_path)\n",
    "    print(f\"Archivo de exclusiones cargado: {len(dic_exclusiones)} categorías con exclusiones\")\n",
    "    \n",
    "    total_patrones_n1 = sum(len(cat[\"patron\"]) + len(cat[\"exacto\"]) for cat in dic_n1.values())\n",
    "    print(f\"Total de patrones N1: {total_patrones_n1}\")\n",
    "    \n",
    "    total_patrones_n2 = 0\n",
    "    for cat_n1, subcats in dic_n2.items():\n",
    "        for subcat, tipos in subcats.items():\n",
    "            total_patrones_n2 += len(tipos[\"patron\"]) + len(tipos[\"exacto\"])\n",
    "    print(f\"Total de patrones N2: {total_patrones_n2}\")\n",
    "    \n",
    "    total_patrones_n3 = 0\n",
    "    for cat_n1, subcats_n2 in dic_n3.items():\n",
    "        for subcat_n2, subcats_n3 in subcats_n2.items():\n",
    "            for subcat_n3, tipos in subcats_n3.items():\n",
    "                total_patrones_n3 += len(tipos[\"patron\"]) + len(tipos[\"exacto\"])\n",
    "    print(f\"Total de patrones N3: {total_patrones_n3}\")\n",
    "    \n",
    "    # Mostrar resumen de exclusiones\n",
    "    total_exclusiones = sum(len(exclusiones) for exclusiones in dic_exclusiones.values())\n",
    "    print(f\"Total de patrones de exclusión: {total_exclusiones}\")\n",
    "    for categoria, exclusiones in dic_exclusiones.items():\n",
    "        print(f\"  - {categoria}: {len(exclusiones)} exclusiones\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar los archivos de patrones: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"Iniciando procesamiento de comentarios...\")\n",
    "inicio = datetime.now()\n",
    "filas_resultantes = []\n",
    "total = len(df)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if idx % 100 == 0 and idx > 0:\n",
    "        print(f\"Procesados {idx}/{total} comentarios ({idx/total*100:.1f}%)...\")\n",
    "        \n",
    "    comentario_original = row[\"COMENTARIO_NPS\"] if not pd.isna(row[\"COMENTARIO_NPS\"]) else \"\"\n",
    "    comentario_limpio = limpiar_texto(comentario_original)\n",
    "    \n",
    "    fecha_transaccion = row[\"FEC_TRANSACCION\"]\n",
    "    codmes = \"\"\n",
    "    if not pd.isna(fecha_transaccion):\n",
    "        try:\n",
    "            if isinstance(fecha_transaccion, str):\n",
    "                fecha_dt = pd.to_datetime(fecha_transaccion)\n",
    "            else:\n",
    "                fecha_dt = fecha_transaccion\n",
    "                \n",
    "            codmes = fecha_dt.strftime(\"%Y%m\")\n",
    "        except:\n",
    "            codmes = \"\"\n",
    "    \n",
    "    if comentario_limpio == \"\":\n",
    "        cats_n1 = [\"Sin Comentario\"]\n",
    "        cats_n2 = [\"Sin Comentario\"]\n",
    "        cats_n3 = [\"Sin Comentario\"]\n",
    "        sentimiento = \"neutral\"\n",
    "    else:\n",
    "        sentimiento = analizar_sentimiento_mejorado(comentario_limpio)\n",
    "        \n",
    "        es_generico = es_comentario_generico(comentario_limpio)\n",
    "        num_palabras = len(comentario_limpio.split())\n",
    "        \n",
    "        if num_palabras <= 7 and num_palabras > 0:  \n",
    "            cats_n1 = obtener_categorias_n1_mejorado(comentario_limpio, dic_n1, dic_exclusiones)\n",
    "            if not cats_n1:  \n",
    "                cats_n1 = [\"noespecifica\"]\n",
    "        else:\n",
    "            cats_n1 = obtener_categorias_n1_mejorado(comentario_limpio, dic_n1, dic_exclusiones)\n",
    "            \n",
    "            if not cats_n1:\n",
    "                cats_n1 = [\"Sin categoría N1\"]\n",
    "    \n",
    "    for c1 in cats_n1:\n",
    "        if c1 == \"Sin Comentario\" or c1 == \"Sin categoría N1\" or c1 == \"noespecifica\":\n",
    "            cats_n2 = [\"Sin categoría N2\"]\n",
    "            cats_n3 = [\"Sin categoría N3\"]\n",
    "        else:\n",
    "            cats_n2 = obtener_subcategorias_n2_mejorado(comentario_limpio, c1, dic_n2)\n",
    "            \n",
    "            if not cats_n2:\n",
    "                cats_n2 = [\"Sin categoría N2\"]\n",
    "                cats_n3 = [\"Sin categoría N3\"]\n",
    "            else:\n",
    "                temp_cats_n3 = []\n",
    "                for c2 in cats_n2:\n",
    "                    if c2 == \"Sin categoría N2\":\n",
    "                        temp_cats_n3.append(\"Sin categoría N3\")\n",
    "                    else:\n",
    "                        c3_list = obtener_subcategorias_n3_mejorado(comentario_limpio, c1, c2, dic_n3)\n",
    "                        if c3_list:\n",
    "                            temp_cats_n3.extend(c3_list)\n",
    "                        else:\n",
    "                            temp_cats_n3.append(\"Sin categoría N3\")\n",
    "                cats_n3 = temp_cats_n3\n",
    "        \n",
    "        for i, c2 in enumerate(cats_n2):\n",
    "            c3 = cats_n3[i] if i < len(cats_n3) else \"Sin categoría N3\"\n",
    "            \n",
    "            fila_resultado = {col: row[col] for col in row.index if col in row}\n",
    "            \n",
    "            fila_resultado.update({\n",
    "                \"CODMES\": codmes,\n",
    "                # \"NPS_Comentario\": comentario_original,\n",
    "                \"Comentario_Limpio\": comentario_limpio,\n",
    "                \"Categoria_N1\": c1,\n",
    "                \"Categoria_N2\": c2,\n",
    "                \"Categoria_N3\": c3,\n",
    "                \"Sentimiento\": sentimiento,\n",
    "                \"Palabras\": len(comentario_limpio.split()) if comentario_limpio else 0,\n",
    "                \"Usa_Exclusiones\": \"Sí\"  # Nueva columna para indicar que se utilizó la lógica de exclusiones\n",
    "            })\n",
    "            \n",
    "            filas_resultantes.append(fila_resultado)\n",
    "\n",
    "df_categorizado = pd.DataFrame(filas_resultantes)\n",
    "\n",
    "fin = datetime.now()\n",
    "tiempo_ejecucion = (fin - inicio).total_seconds()\n",
    "\n",
    "print(\"\\n===== RESULTADOS DE LA CLASIFICACIÓN =====\")\n",
    "print(f\"Total registros procesados: {total}\")\n",
    "print(f\"Tiempo de ejecución: {tiempo_ejecucion:.2f} segundos ({tiempo_ejecucion/60:.2f} minutos)\")\n",
    "\n",
    "print(\"\\nDistribución por categoría N1:\")\n",
    "for cat, count in df_categorizado[\"Categoria_N1\"].value_counts().items():\n",
    "    print(f\"  - {cat}: {count} ({count/len(df_categorizado)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nDistribución por categoría N2:\")\n",
    "for cat, count in df_categorizado[\"Categoria_N2\"].value_counts().head(10).items():\n",
    "    print(f\"  - {cat}: {count} ({count/len(df_categorizado)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nDistribución por categoría N3:\")\n",
    "for cat, count in df_categorizado[\"Categoria_N3\"].value_counts().head(10).items():\n",
    "    print(f\"  - {cat}: {count} ({count/len(df_categorizado)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nDistribución de sentimiento:\")\n",
    "for sent, count in df_categorizado[\"Sentimiento\"].value_counts().items():\n",
    "    print(f\"  - {sent}: {count} ({count/len(df_categorizado)*100:.1f}%)\")\n",
    "\n",
    "excel_output = \"/Workspace/Users/jenisalvarado@bcp.com.pe/GENERACION BASES | CARGA DE RESPUESTAS | TIPIFICACION COMENTARIOS/Herramienta_comentarios/EXPORT_topicos_digitales_nuevaversion.xlsx\"\n",
    "\n",
    "try:\n",
    "    print(f\"\\nGuardando resultados en Excel: {excel_output}\")\n",
    "    df_categorizado.to_excel(excel_output, index=False, encoding=\"Windows-1252\")\n",
    "    print(\"Archivo Excel guardado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar en Excel: {str(e)}\")\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    backup_path = f\"/Workspace/Users/jenisalvarado@bcp.com.pe/GENERACION BASES | CARGA DE RESPUESTAS | TIPIFICACION COMENTARIOS/Herramienta_comentarios/EXPORT_topicos_digitales_{timestamp}.csv\"\n",
    "    try:\n",
    "        print(f\"Intentando guardar como CSV en: {backup_path}\")\n",
    "        df_categorizado.to_csv(backup_path, index=False, encoding=\"utf-8\")\n",
    "        print(\"Archivo CSV de respaldo guardado correctamente.\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Error al guardar archivo de respaldo: {str(e2)}\")\n",
    "\n",
    "print(\"\\nProceso completado.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) Neil - TextAnalytics 2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}